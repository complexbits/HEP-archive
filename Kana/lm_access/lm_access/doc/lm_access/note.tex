\documentclass[12pt]{article}
\topmargin -.5in		% 1 inch at top of page
\textheight 9in			% 9 inches text ==> 1 inch bottom margin
\oddsidemargin 0in		% 1.5 inch left margin
\textwidth 6.5in		% ~6 inches text ==> 1 inch right margin
\evensidemargin 0in		% does correct thing for TWOSIDE
\pagestyle{myheadings}
\markright{\hfill D\O\ Note \#3969~\quad p.~}
\include{epsf}
\include{pstricks}
\begin{document}
\title{Accessing Triggered Luminosity Information \\ via Flat Files}
\author{Sung Hwan Ahn,$^3$ 
	Oleksiy Atramentov,$^2$ 
	Michael Begel,$^7$ \\
	Gregor Geurkov,$^1$ 
	John Hauptman,$^2$ 
	Alexander Kup\v{c}o,$^6$ \\
	Seh Wook Lee,$^3$ 
	Prolay Kumar Mal,$^8$ 
	Jae Won Park,$^3$ \\
	Richard Partridge,$^1$ 
	Heidi Schellman,$^5$ 
	Marco Verzocchi$^4$
\\
\\ $^1${\it\small Brown University, Providence, Rhode Island}
\\ $^2${\it\small State University, Ames, Iowa}
\\ $^3${\it\small Korea University, Seoul, Korea}
\\ $^4${\it\small University of Maryland, College Park, Maryland}
\\ $^5${\it\small Northwestern University, Evanston, Illinois}
\\ $^6${\it\small Center for Particle Physics, Prague, Czech Republic}
\\ $^7${\it\small University of Rochester, Rochester, New York}
\\ $^8${\it\small Tata Institute of Fundamental Research, Mumbia, India}
}
%\date
\maketitle
\thispagestyle{myheadings}
\markright{\hfill D\O\ Note \#3969~\quad p.~}

\begin{quote}
Include abstract here.
\end{quote}

\section{Introduction}

Other documents in this series describe the measurement of delivered
luminosity~\cite{3970}, triggered luminosity~\cite{3971}, recorded
luminosity~\cite{3972}, and the access methods for normalization
information from SAM~\cite{3465,3937}.

\section{Luminosity Calculation}

The luminosity block is the fundamental unit of time for the
luminosity measurement.  Each block is indexed by the luminosity block
number (LBN), which monotonically increases throughout Run~2.  The LBN
is incremented upon run or store transitions, by request, or after
60~seconds have elapsed.  The time span was chosen based on numerous
constraints in the luminosity, trigger, and DAQ systems.  The time
period is short enough so that the instantaneous luminosity is
effectively constant during each luminosity block, introducing
negligible uncertainty into the measurement of the luminosity due to
the width of the time slice.  Raw data files (partitions) are opened
and closed on LBN boundaries.  The luminosity calculation, detailed in
D\O~Notes~3970, 3971,~and 3972~\cite{3970,3971,3972}, is made
independently for each LBN.  Results are averaged over the luminosity
block.

Unfortunately events can be lost at every stage of the read-out
process~\cite{3972}.  It is difficult to correct the luminosity for
these losses on a trigger-by-trigger basis given the large rejection
factors.  The solution is to have low-bias triggers not rejected by
the trigger system; these are used to track losses and correct the
luminosity.  The {\it zero bias} trigger fires based on a clock
pattern; there is no reliance on detector information.  The {\it min
bias} trigger is defined like the {\it zero bias} trigger with the
additional requirement of a luminosity signal~\cite{3973}.  Every
normalized exposure group must have both a {\it zero bias} and {\it
min bias} trigger.

The final measure of recorded luminosity is taken from the event
catalogs sent to the $\cal L$DAQ~\cite{XXXX-LDAQ} by the datalogging
process~\cite{3982}.  These catalogs are also sent to SAM~\cite{3465}
for the offline data processing.  The event catalogs contain, for
every event in the partition, the event number, LBN, and L1, L2, and
L3 trigger masks.  Using information made available to both the $\cal
L$DAQ and the Runs Summary database, the {\it zero bias} and {\it min
bias} triggers are identified and summed for each luminosity block.
This count of recorded triggers is compared to the number of
L1~accepts and used to correct the luminosity for every trigger as
follows,
\begin{equation}
{\cal L}_{recorded}(n) = {\# zero\;bias_{recorded} + \#
min\;bias_{recorded} \over \# zero\;bias_{L1} + \# min\;bias_{L1}}
\;{\cal L}_{L1}(n),
\label{eq:recorded}
\end{equation}
where ${\cal L}_{L1}(n)$ is the luminosity of trigger~$n$
at~L1. (There are no prescales implemented at the other levels of the
trigger, so ${\cal L}_{L3} = {\cal L}_{L2} = {\cal L}_{L1}$.)  It must
be noted that this correction methodology requires that the {\it zero
bias} and {\it min bias} triggers are treated exactly like the other
triggers --- differences bias the recorded luminosity.  Any losses not
accounted for by this method must be included in the trigger
efficiency.

Other losses can arise during the reconstruction process due to crashes
of the reconstruction software. In order to catch those cases a number of
events is counted for every LBN in both raw files and reconstructed files
(so far root tuples). If the number of events does not agree the LBN
is marked as a bad block from the point of view of reconstructed luminosity
otherwise reconstructed luminosity is the same as recorded

\begin{equation}
{\cal L}_{reconstructed}(n) = {\cal L}_{recorded}(n)\,,\qquad 
\hbox{if}\qquad \#events_{reconstructed} = \#events_{recorded}
\label{eq:reconstructed}
\end{equation}

\section{Normalizing the Data}

An access to the luminosity information in the physics analysis of the
D\O\ data is provided by {\tt lm\_access} package. The package can be
obtained from D\O\  CVS repository in standard way, also the
documentation is available on WWW  pages of Luminosity ID group.

\subsection{Flat Files}

The smallest unit of time in which the luminosity is provided is a
luminosity block. Each LBN has its own (flat) file that contains all
the information necessary to calculate integrated luminosity in the
LBN per trigger. If the file for a given LBN does not exists it means
that the data for this LBN cannot be normalised at all. The luminosity
files are currently cached on both d0mino and clued0 in the directory
{\tt /home/begel/stage2} and they are regularly updated.

\subsection{Lm\_access API}

All access to the luminosity information goes through class {\tt
LumFileMap}.  It keeps in the memory list of LBNs associated with the
data, organises them according to the version of the reconstruction
software, provides a method that gives a status of LBNs, and
calculates total luminosity per trigger.


In the constructor user specifies the list of triggers that he wants
to normalise and also the type of luminosity (triggered, recorded, or
reconstructed as described in the notes ~\cite{3971}, ~\cite{3972}).

In order to calculate reconstructed luminosity the LBNs (or data
files) has to be grouped according to the version of the release of
the reconstruction software. Introducing new data file (or release, or
some other general group of LBNs) is done by

\begin{flushleft}
\hspace*{4mm} {\tt LumFileMap::add(const std::string\& fileID, const
LumFile\& f = LumFile())}
\end{flushleft}

where the string {\tt fileID} is some unique identifier of the group
 of LBNs (for example LBNs from one data file). The second parameter
 {\tt f} specifies what is the type of the data files and what was the
 version of the reconstruction software. There is no need to specify
 the release version and the second parameter can be omitted in the
 case when the type of the required luminosity is triggered or
 recorded.

Before any information about particular LBN can be access the LBN flat file has to be downloaded into the memory. Method
\begin{flushleft}
\hspace*{4mm} {\tt int LumFileMap::downloadLBN(const std::string\& fileID, int lbn)}
\end{flushleft}
adds one particular luminosity block {\tt lbn} into the list of known LBNs and
associates the LBN with the group {\tt fileID}.

After the LBN is downloaded into the memory the user can check whether the data for a given trigger can be normalised. If the function
\begin{flushleft}
\hspace*{4mm} {\tt int LumFileMap::isGoodLBN(const std::string\& fileID, int lbn,
\hspace*{61.82mm}const std::string\& trigger)}
\end{flushleft}
returns one the data can be normalised. If it returns zero the data from the given LBN and trigger cannot be normalised at all and they have to be removed from the analysis.

Finally, a function
\begin{flushleft}
\hspace*{4mm} {\tt double LumFileMap::luminosity(const std::string\& trigger)}
\end{flushleft}
returns total luminosity in $\mu\hbox{b}^{-1}$ for a given trigger and for
all downloaded LBNs for which the status is good.

A simple example that shows how to get luminosity and cross section for one
particular trigger can be found in the documentation of the {\tt lm\_access}
package.

\subsection{Luminosity for stripped data}

To compute luminosity for some data sample correctly it is
very important that list of LBNs downloaded into the memory corresponds
to this sample.

The situation is quite simple in the case of the official ROOT tuples
made from {\tt reco} files. So far all the data are stored in one stream.
Moreover, according to the definition of the recorded luminosity, 
eq.~(\ref{eq:recorded}), there has to be at least one event from zero bias
or minimum bias trigger in the LBN in order to have some recorded luminosity.
Therefore it is enough to download every LBN that occurs in the data sample
as it is done in the example in the documentation of the {\tt lm\_access}
package.

In the case of stripped data files the situation is more complicated 
because stripping is made in various physics groups in different ways.
The approach described above cannot be used usually since there is no guaranty 
that there is at least one event per LBN in the stripped data files.
It is up to the groups to keep the list of original LBNs that corresponds to
their stripped sample and provide tools that allows to download this list
in the data analysis.

\newpage
% 
% Bibliography 
%
\bibliographystyle{../bibliography/lmid}
\bibliography{../bibliography/lmid} 

\end{document}
